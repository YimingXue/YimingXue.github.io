<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">
<head>
  <link href="https://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="generator" content="Hugo 0.72.0" />

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title> &middot; My New Hugo Site</title>
  <meta name="description" content="" />

  
  <link type="text/css" rel="stylesheet" href="http://YimingXue.github.io/css/print.css" media="print">
  <link type="text/css" rel="stylesheet" href="http://YimingXue.github.io/css/poole.css">
  <link type="text/css" rel="stylesheet" href="http://YimingXue.github.io/css/syntax.css">
  <link type="text/css" rel="stylesheet" href="http://YimingXue.github.io/css/hyde.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Abril+Fatface|PT+Sans:400,400i,700">


  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/favicon.png">

  
  
</head>

  <body class=" ">
  <aside class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <a href="http://YimingXue.github.io/"><h1>My New Hugo Site</h1></a>
      <p class="lead">
      An elegant open source and mobile first theme for <a href="http://hugo.spf13.com">hugo</a> made by <a href="http://twitter.com/mdo">@mdo</a>. Originally made for Jekyll.
      </p>
    </div>

    <nav>
      <ul class="sidebar-nav">
        <li><a href="http://YimingXue.github.io/">Home</a> </li>
        
      </ul>
    </nav>

    <p>&copy; 2020. All rights reserved. </p>
  </div>
</aside>

    <main class="content container">
    <div class="post">
  <h1></h1>
  <time datetime=0001-01-01T00:00:00Z class="post-date">Mon, Jan 1, 0001</time>
  <h1 id="熵与信息增益">熵与信息增益</h1>
<h2 id="信息量">信息量</h2>
<ul>
<li>信息量是用来衡量一个事件的不确定性的。一个事件发生的概率越大，不确定性越小，则它所携带的信息量就越小</li>
<li>公式：
<ul>
<li>$I(x_0)=-log(p(x_0))$</li>
</ul>
</li>
</ul>
<h2 id="熵">熵</h2>
<ul>
<li>熵是用来衡量一个系统的混乱程度的，代表一个系统中信息量的总和；信息量总和越大，表明这个系统不确定性就越大</li>
<li>信息量用来衡量一个事件的不确定度，熵则用来衡量一个系统（也就是所有事件）的不确定度</li>
<li>度量系统中所有事件的不确定度使用的是期望。所以熵是信息量的期望值，它是一个随机变量的确定性的度量，熵越大，变量的取值越不确定；反之，熵越小变量取值就越稳定</li>
<li>公式：
<ul>
<li>$H(X)=-\sum_{x\in X}^{}{p(x)log(p(x))}$</li>
<li>$H(X)=-\int{}_{x\in X}{p(x)log(p(x))d_x}$</li>
</ul>
</li>
</ul>
<h2 id="条件熵">条件熵</h2>
<ul>
<li>条件熵定义为在随机变量X发生的前提下，随机变量Y发生所带来的熵，用$H(Y|X)$表示，用来衡量在已知随机变量X的前提下随机变量Y的不确定性</li>
<li>公式：
<ul>
<li>$H(Y|X)=H(X,Y)-H(X)=-\sum_{x,y}{p(x,y)log(p(y|x))}$，(X,Y)发生所包含的熵减去X单独发生包含的熵</li>
</ul>
</li>
</ul>
<h2 id="相对熵relative-entropy">相对熵(relative entropy)</h2>
<ul>
<li>相对熵(relative entropy)又称为KL散度(Kullback-Leibler divergence)，KL距离，是两个随机分布距离的度量。记为$D_{KL}(p||q)$，表示在真实分布为p的前提下，使用q分布进行编码相对于使用真实分布p进行(即最优编码)所多出来的bit数</li>
<li>公式：
<ul>
<li>$D_{KL}(p||q)=E_p[log\frac{p(x)}{q(x)}]=\sum_{x\in X}{p(x)log\frac{p(x)}{q(x)}}=H_p(q)-H(p)$，$H_p(q)$表示在p分布下，使用q进行编码需要的bit数；$H(p)$表示对与真实分布p所需要的最小编码bit数</li>
</ul>
</li>
</ul>
<h2 id="交叉熵">交叉熵</h2>
<ul>
<li>
<p>交叉熵反应的是分布p和q的相似程度</p>
</li>
<li>
<p>公式：</p>
<ul>
<li>
<p>$CE(H(p,q))=E_p(-log(q))=\sum_{x\in X}{p(x)log(q(x))}=H(p)+D_{KL}(p||q)$</p>
<p>​                                                     $=-[plog(q)+(1-p)log(1-q)]$</p>
<p>​                                                     $=-[ylog(h_{\theta}{x})+(1-y)log(1-h_{\theta}(x))]$</p>
</li>
</ul>
</li>
<li>
<p>==在TensorFlow中实现交叉熵==</p>
<ul>
<li><code>cross_entropy = -tf.reduce_mean(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0)))</code></li>
<li>其中<code>y_</code>表示期望的输出，<code>y</code>表示实际的输出（概率值），<code>*</code>为矩阵元素间相乘</li>
<li>这里要注意一点，平均交叉熵应该是先计算batch中每一个样本的交叉熵后取平均计算得到的，而利用<code>tf.reduce_mean</code>函数其实计算的是整个矩阵的平均值，这样做的结果会有差异，但并不改变实际意义。</li>
</ul>
</li>
</ul>
<h2 id="信息增益">信息增益</h2>
<h2 id="互信息">互信息</h2>
<h2 id="信息增益比">信息增益比</h2>
<p>参考文献：</p>
<ul>
<li><a href="https://blog.csdn.net/xg123321123/article/details/52864830">熵与信息增益</a></li>
</ul>
<h1 id="non-maximum-suppression">Non-Maximum Suppression</h1>
<h2 id="简介">简介</h2>
<p>非极大值抑制顾名思义就是抑制不是极大值的元素，搜索局部的极大值。</p>
<h2 id="在目标检测中的实现">在目标检测中的实现</h2>
<p>针对目标检测任务中，非极大值抑制就是根据==预测出来的box的坐标信息和置信度==，从中找到置信度比较高的bounding box，具体过程如下：</p>
<ul>
<li>根据score进行排序，把score最大的bounding box拿出来</li>
<li>计算其余bounding box与这个box的IoU，然后去除IoU大于设定的阈值的bounding box</li>
<li>重复上述两个过程，直到候选bounding box为空</li>
</ul>
<p>总结来说就是在一堆预测框中找出一些局部最大值，所以要把和这些局部最大值的IoU比较大的去除掉，这样就可以得到一些置信度很大但是IoU比较小的bounding box</p>
<h1 id="hard-negative-mining">Hard Negative Mining</h1>
<p>在目标检测中我们会计算生成的proposals和ground truth之间的IoU，如果IoU超过一定的阈值则认为是正样本，剩下的就是负样本，然后再送入网络进行训练。但是这样会产生正样本数量远远小于负样本的问题，这样训练出来的分类器的效果是有限的，会出现很多False Positive，所以把其中得分较高的False Positive作为所谓的Hard Negative，将这些作为负样本扔进网络再训练一次从而加强分类器判别假阳性的能力。</p>
<h1 id="dilatedatrous-convolution">Dilated/Atrous Convolution</h1>
<p>空洞卷积是针对==语义分割问题==中下采样会降低图像分辨率、丢失信息而提出的一种卷积思路。利用空洞卷积扩大感受野，让原本3×3的卷积核，在相同参数量和计算量的下拥有5×5（dilated rate=2）或者更大的感受野，从而无需下采样。需要注意的是空洞的位置全填进去0，填入0之后再卷积即可。</p>
<p>语义分割中为了让卷积核拥有更大的感受野，一般的做法是增加pooling层，但是这样会丢失一部分信息并且图像的分辨率也会更降低。使用空洞卷积可以很好地解决这个问题，在不增加计算量的前提下，感受野变大了并且图像分辨率也没有改变（因为不需要pooling），从而信息也不会丢失。</p>
<h1 id="精确率和召回率">精确率和召回率</h1>
<ul>
<li>精确率是针对预测结果而言的，它表示的是预测为正样本中有多少是真正的正样本。那么预测为正就有两种可能，一种是把正类预测为正类（TP），另一种是把负类预测为正类（FP），也就是$P=\frac{TP}{TP+FP}$</li>
<li>召回率是针对我们原来的样本而言的，它表示的是样本中的正例有多少被预测正确了。那也有两种可能，一种是把原来的正类预测为正类（TP），另一种是把原来的正类预测为负类（FN），即$R=\frac{TP}{TP+FN}$</li>
</ul>
<h1 id="voc数据集map计算">VOC数据集mAP计算</h1>
<p>检测出来的bbox包含score和bbox，按照score降序排序，所以每添加一个样本，就代表阈值降低一点（真实情况下score降低，IoU不一定降低）。这样就是可以有很多种阈值，每个阈值情况下计算一个prediction和recall。</p>
<h2 id="图像检测的ap">图像检测的AP</h2>
<ul>
<li>
<p>训练过程</p>
<ol>
<li>使用区域选择算法（如SS）得到候选区域</li>
<li>对于候选区域，计算每一个候选区域和GT的IoU</li>
<li>设定一个IoU阈值，大于这个阈值的为正样本，小于的为负样本，由此得到训练数据</li>
</ol>
</li>
<li>
<p>测试过程</p>
<ol>
<li>将给定的测试集（正负样本），通过分类器，算出每一张图像是正样本的score</li>
<li>设定一个score阈值，大于此值的视为正样本，小于的作为负样本</li>
<li>根据上一步的结果可以计算出来精确率和召回率</li>
<li>调节score阈值，算出召回率从0到1时的精确率，得到一条曲线</li>
<li>计算曲线下面的面积则为AP</li>
</ol>
</li>
</ul>
<h1 id="adam优化算法">Adam优化算法</h1>
<h2 id="adam的参数配置">Adam的参数配置</h2>
<ul>
<li>alpha：学习率（步长因子），控制权重的更新比率。</li>
<li>beta1：一阶矩估计的指数衰减率。</li>
<li>beta2：二阶矩估计的指数衰减率。该超参数在稀疏梯度（如NLP或计算机视觉任务）中应该设置接近于1的数。</li>
<li>epsilon：防止在实现过程中除以零，应设置非常小的数。</li>
</ul>
<p>==Caffe中默认参数设定==：learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08</p>
<h1 id="图片的数据增强方法">图片的数据增强方法</h1>
<p>在深度学习中，为了防止出现过拟合（Overfitting），通常我们需要输入充足的数据量。如果数据量比较小，可以对原有的图像数据进行数据扩张。</p>
<p>参考文献：</p>
<p><a href="https://blog.csdn.net/Yaphat/article/details/54098867">图片的数据增强（Data Augmentation）方法</a></p>
<h1 id="batchnorm层与scale层">BatchNorm层与Scale层</h1>
<p>BatchNorm主要有两方面作用：</p>
<ul>
<li>对输入进行归一化，减去均值，除以方差。虽然数据输入的时候对原图进行了同样的操作，但是经过卷积层后，特征图会发生变化。这一部分对应的是Caffe BatchNorm层。</li>
<li>归一化后进行缩放和平移。这一部分对应Caffe Scale层，Scale层设置bias_term=True。</li>
</ul>
<p>参考文献：</p>
<p><a href="https://blog.csdn.net/zziahgf/article/details/78843350">Caffe 源码 - BatchNorm 层与 Scale 层</a></p>
<h1 id="过拟合解决方法">过拟合解决方法</h1>
<p>过拟合一般是因为模型过于复杂从而很好地“记住了”训练样本，但是对新的测试样本误差会很大。过拟合的判断标准就是训练误差很小，但是测试误差很大。</p>
<h2 id="增加数据">增加数据</h2>
<p>大部分产生过拟合的原因是数据量太少，所以在训练一些大型网络的时候，我们会对数据进行扩充，例如目标检测任务中的随机裁剪、随机翻转等。</p>
<h2 id="运用正则化">运用正则化</h2>
<p>监督机器学习问题无非就是在规则化参数的同时最小化误差，最小化误差是为了让我们的模型拟合训练数据，而规则化参数是为了防止模型过于拟合训练数据。</p>
<ul>
<li>L0范数与L1范数
<ul>
<li>L0和L1范数可以实现稀疏，L1因为具有比L0更好的优化求解的特性而被广泛应用
<ul>
<li>L0范数是指向量中非0的元素的个数</li>
<li>L1范数是指向量中各个元素绝对值之和（L1范数是L0范数的最优凸近似，而且它比L0范数要容易优化求解）</li>
</ul>
</li>
<li>追求稀疏化的原因
<ul>
<li>特征选择：稀疏性可以实现特征的自动选择，它会学习地去掉这些没有信息的特征，也就是把这些特征对应的权重置为零</li>
<li>可解释性：模型更容易解释</li>
</ul>
</li>
</ul>
</li>
<li>L2范数(weight decay)
<ul>
<li>定义：L2范数是指向量各元素的平方和然后求平方根，在令L2范数的正则项最小过程中，可以使得weight中每个元素都很小，都接近于0（注意不是像L1范数那样等于0），越小的参数说明模型越简单，越简单的模型则越不容易产生过拟合现象。</li>
<li>L2范数优点：
<ul>
<li>学习理论角度：L2范数可以防止过拟合，提升模型的泛化能力</li>
<li>优化计算角度：L2范数有助于处理condition number不好的情况下矩阵求逆很困难的问题</li>
</ul>
</li>
</ul>
</li>
<li>总结L1范数和L2范数
<ul>
<li>L1范数会趋向于产生少量的特征，而其他的特征都是0</li>
<li>L2会选择更多的特征，这些特征都会接近于0</li>
</ul>
</li>
</ul>
<h2 id="dropout">Dropout</h2>
<p>在训练的过程中随机忽略一些神经元和神经连接，强迫网络在每次训练时的预测结果都不会依赖于其中部分特征的神经元。</p>
<h1 id="梯度消失爆炸">梯度消失、爆炸</h1>
<p>参考资料：</p>
<ul>
<li><a href="https://blog.csdn.net/qq_25737169/article/details/78847691">详解机器学习中的梯度消失、爆炸原因及其解决方法</a></li>
<li></li>
</ul>
<p>Of late, A lot of effort has been spent on solving multiple instance learning (MIL) problem using neural network. In this paper, we propose a new MIL network named Attention-GSR, which is an improved version of Attention network. Because of using Gumbel-Softmax Relaxation In the stage of predicting instance weight, the network will be forced to focus more on the instances that play an absolute role in the bag classification and it will converge more easily during the training process. Therefore, the classification effect of bag is improved under the premise of not affecting the instance classification result. Experiments are conducted on benchmark MIL datasets and a real-life histopathology dataset. Results show that our method outperforms the previous state of the art.</p>

</div>


    </main>

    
      
    
  </body>
</html>
